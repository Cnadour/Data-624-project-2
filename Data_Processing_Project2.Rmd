---
title: "Project2"
date: "2024-12-09"
output: word_document
---

```{r}
library(dplyr)
library(readxl)
library(tidyr)

```

## R Markdown


```{r}
# Load the specific sheet from the first Excel file
student_data <- read_excel("C:\\Users\\Owner\\Downloads\\StudentData.xlsx", sheet = "Subset")

# Load the specific sheet from the second Excel file
student_evaluation <- read_excel("C:\\Users\\Owner\\Downloads\\StudentEvaluation.xlsx", sheet = "Subset (2)")

```

## Including Plots
```{r}
# Inspect the structure of the data
glimpse(student_data)
glimpse(student_evaluation)
```

```{r}
# Check for missing values
sum(is.na(student_data))
sum(is.na(student_evaluation))
```

```{r}
# View a summary of the data
summary(student_data)
summary(student_evaluation)
```

```{r}
head(student_data)
head(student_evaluation)

```

```{r}
# Remove rows with missing data
student_data <- student_data %>% drop_na()
student_evaluation <- student_evaluation %>% drop_na()

```

```{r}

# Check for missing values
sum(is.na(student_data))
sum(is.na(student_evaluation))


```

```{r}
# Standardize column names
student_data <- student_data %>% rename_all(tolower) %>% rename_all(gsub, pattern = " ", replacement = "_")
student_evaluation <- student_evaluation %>% rename_all(tolower) %>% rename_all(gsub, pattern = " ", replacement = "_")


```

```{r}
# Remove duplicates
student_data <- student_data %>% distinct()
student_evaluation <- student_evaluation %>% distinct()
```

```{r}
# Convert character columns to factors and ensure date columns are correctly formatted
student_data <- student_data %>%
  mutate(across(where(is.character), as.factor))

student_evaluation <- student_evaluation %>%
  mutate(across(where(is.character), as.factor))
```

```{r}
# Data types
str(student_data)

```

### Data Preprocessing

```{r}
library(caret)
library(MASS) # For Yeo-Johnson transformation
library(corrr) # For correlation analysis
library(ggplot2)
library(tibble) # For rownames_to_column
```


```{r}
# Step 1: Identify numeric columns for transformations
numeric_columns <- student_data %>% select_if(is.numeric)

# Step 2: Apply Yeo-Johnson transformation (for non-normality)
preProcess_numeric <- preProcess(numeric_columns, method = "YeoJohnson")
student_data[names(numeric_columns)] <- predict(preProcess_numeric, numeric_columns)

# Step 3: Check for outliers using interquartile range (IQR) method
check_outliers <- function(df) {
  df %>%
    summarise(across(where(is.numeric), ~ sum(. > (quantile(., 0.75) + 1.5 * IQR(.)) |
                                      . < (quantile(., 0.25) - 1.5 * IQR(.)), na.rm = TRUE)))
}

outlier_counts <- check_outliers(student_data)
outlier_counts

# Step 4: Scale numeric data using robust scaling (median and IQR)
robust_scale <- function(df) {
  df %>% mutate(across(where(is.numeric), ~ (. - median(.)) / IQR(.), .names = "{.col}_scaled"))
}

student_data <- robust_scale(student_data)

# Step 5: Check for multicollinearity using correlation matrix
cor_matrix <- student_data %>% select_if(is.numeric) %>% cor()

# Visualize the correlation matrix
cor_matrix_plot <- cor_matrix %>%
  as.data.frame() %>%
  rownames_to_column(var = "Variable") %>%
  pivot_longer(-Variable, names_to = "Correlated_Variable", values_to = "Correlation") %>%
  filter(Variable != Correlated_Variable, abs(Correlation) > 0.7) %>%
  ggplot(aes(x = Variable, y = Correlated_Variable, fill = Correlation)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  theme_minimal() +
  labs(title = "Correlation Matrix", x = "", y = "")

print(cor_matrix_plot)

# Identify highly correlated variables (threshold = 0.7)
find_highly_correlated <- function(cor_matrix, threshold = 0.7) {
  cor_pairs <- as.data.frame(as.table(cor_matrix)) %>%
    filter(Var1 != Var2, abs(Freq) > threshold)
  cor_pairs
}
high_corr <- find_highly_correlated(cor_matrix)
high_corr

# Drop one variable from each highly correlated pair
vars_to_remove <- unique(high_corr$Var2) # Replace with actual variable names if needed
student_data <- student_data %>% select(-all_of(vars_to_remove, .env = environment()))

# Step 6: Reassess normality, outlier counts, and multicollinearity
# Normality after transformation
shapiro_test_results <- lapply(student_data %>% select_if(is.numeric), shapiro.test)
normality_summary <- sapply(shapiro_test_results, function(x) x$p.value)
normality_summary

# Outlier reassessment
outlier_counts_after <- check_outliers(student_data)
outlier_counts_after

# Correlation reassessment
cor_matrix_after <- student_data %>% select_if(is.numeric) %>% cor()

# Ensure multicollinearity is addressed
cor_matrix_plot_after <- cor_matrix_after %>%
  as.data.frame() %>%
  rownames_to_column(var = "Variable") %>%
  pivot_longer(-Variable, names_to = "Correlated_Variable", values_to = "Correlation") %>%
  filter(Variable != Correlated_Variable, abs(Correlation) > 0.7) %>%
  ggplot(aes(x = Variable, y = Correlated_Variable, fill = Correlation)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  theme_minimal() +
  labs(title = "Correlation Matrix (After Adjustment)", x = "", y = "")

print(cor_matrix_plot_after)

# Save the preprocessed data for modeling
write.csv(student_data, "preprocessed_student_data.csv", row.names = FALSE)
```





